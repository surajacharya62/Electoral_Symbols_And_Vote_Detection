{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Oslo\\\\OsloMet\\\\Fourth semester\\\\Electoral_Symbols_And_Vote_Detection_MLOPS\\\\Electoral_Symbols_And_Vote_Detection\\\\research\\\\faster-rcnn'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Oslo\\\\OsloMet\\\\Fourth semester\\\\Electoral_Symbols_And_Vote_Detection_MLOPS\\\\Electoral_Symbols_And_Vote_Detection'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  #-------initializing the model----- \n",
    "\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class EvaluationConfig:\n",
    "    root_dir: Path\n",
    "    path_of_model: Path\n",
    "    test_images_path: Path\n",
    "    annotations_path: Path\n",
    "    faster_rcnn_files_path: Path\n",
    "    all_params: dict\n",
    "    mlflow_uri: str\n",
    "    params_image_size: list\n",
    "    params_batch_size: int\n",
    "    classes: int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules.symbol_detection.faster_rcnn.constants import *\n",
    "from src.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "                self,\n",
    "                config_filepath =  CONFIG_FILE_PATH,\n",
    "                params_filepath = PARAMS_FILE_PATH\n",
    "        ):\n",
    "            self.config = read_yaml(config_filepath)\n",
    "            self.params = read_yaml(params_filepath)\n",
    "\n",
    "            create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_evaluation_config(self)->EvaluationConfig:\n",
    "      \n",
    "      config = self.config.trained_models\n",
    "\n",
    "      eval_config = EvaluationConfig(\n",
    "                root_dir = Path(config.root_dir),\n",
    "                path_of_model=Path(config.model_path),\n",
    "                test_images_path=Path(config.test_images_path),\n",
    "                annotations_path=Path(config.annotations_path),\n",
    "                faster_rcnn_files_path=Path(config.faster_rcnn_files_path),\n",
    "                mlflow_uri=\"\",\n",
    "                all_params=self.params,\n",
    "                params_image_size=self.params.IMAGE_SIZE,\n",
    "                params_batch_size=self.params.BATCH_SIZE,\n",
    "                classes=self.params.CLASSES                \n",
    "          )\n",
    "      \n",
    "      return eval_config\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.symbol_detection.faster_rcnn.components.electoral_symbol_dataset import  ElectoralSymbolDataset\n",
    "from modules.symbol_detection.faster_rcnn.components.visualize_symbols_detection import VisualizePrediction\n",
    "from modules.symbol_detection.faster_rcnn.components.compare_bounding_boxes_faster import CompareBoundingBox\n",
    "from modules.symbol_detection.faster_rcnn.components.reshape_data import ReshapeData\n",
    "from modules.symbol_detection.faster_rcnn.components.metrics import Metrics\n",
    "from modules.vote_validation.faster_rcnn.validate_vote_faster import ValidateVote\n",
    "from modules.symbol_detection.faster_rcnn.utils.faster_rcnn_utils import label_to_id,get_transform,collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "\n",
    "class Evalaution:\n",
    "\n",
    "   \n",
    "\n",
    "    def __init__(self, config:EvaluationConfig):\n",
    "        self.config = config\n",
    "        self.true_annotation_labels = label_to_id(self.config.annotations_path)\n",
    "\n",
    "    def get_data_loader(self):\n",
    "\n",
    "        annotation_labels = label_to_id(self.config.annotations_path)\n",
    "        test_set = ElectoralSymbolDataset(        \n",
    "            self.config.test_images_path,\n",
    "            \"single_image\",\n",
    "            self.config.annotations_path,\n",
    "            annotation_labels,\n",
    "            get_transform(train=False),\n",
    "            is_single_image=False \n",
    "        )\n",
    "        \n",
    "        test_data_loader = DataLoader(test_set, batch_size=self.config.params_batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "        return test_set, test_data_loader\n",
    "    \n",
    "    \n",
    "    def get_faster_rcnn_model(self):\n",
    "        \"\"\"\n",
    "        Initializing model  \n",
    "        \"\"\"\n",
    "        model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(pretrained=True)    \n",
    "        # get number of input features for the classifier\n",
    "        in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "        # replace the pre-trained head with a new one\n",
    "        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, self.config.classes) \n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def make_predictions(self,dataset_loader, faster_rcnn_model):\n",
    "        \"\"\"\n",
    "        Make predictions on test images\n",
    "        \"\"\"\n",
    "        \n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')       \n",
    "        faster_rcnn_model.load_state_dict(torch.load(self.config.path_of_model, map_location=device))\n",
    "        faster_rcnn_model.eval()\n",
    "        # test_data_loader = self.get_data_loader()\n",
    "       \n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for images, imageids, imagenames, target in dataset_loader:\n",
    "                images = [image.to(device) for image in images]\n",
    "                outputs = faster_rcnn_model(images)\n",
    "\n",
    "                for output, imageid, imagename in zip(outputs, imageids, imagenames):\n",
    "                    prediction = (output, imageid, imagename)\n",
    "                    predictions.append(prediction)\n",
    "        \n",
    "        test_images_path = self.config.test_images_path\n",
    "        test_images_name = []\n",
    "        for filename in os.listdir(test_images_path):\n",
    "            test_images_name.append(filename) \n",
    "        \n",
    "        return predictions, test_images_name\n",
    "    \n",
    "    \n",
    "    def visualize_predictions(self, predictions, test_set):\n",
    "        \"\"\"\n",
    "            Visualize prediction\n",
    "        \"\"\" \n",
    "            \n",
    "        visualize = VisualizePrediction()        \n",
    "        visualize.visualize_predicted_images(self.config.test_images_path, test_set, predictions, self.true_annotation_labels)\n",
    "    \n",
    "    \n",
    "    def vote_validation(self, test_set, test_images, predictions):\n",
    "        \n",
    "         #-------------Vote Validation\n",
    "\n",
    "        vote_validate = ValidateVote()        \n",
    "        vote_validate.validate_vote(test_set, test_images, predictions, self.true_annotation_labels, self.config.test_images_path)\n",
    "\n",
    "    \n",
    "    def metrics_calculation(self, test_set, predictions):\n",
    "    \n",
    "        #Predictions Bounding Box Comparison        \n",
    "        compare_bboxes = CompareBoundingBox()\n",
    "       \n",
    "        compare_bboxes.labels(test_set, predictions, self.true_annotation_labels) \n",
    "\n",
    "        #Data Reshaping\n",
    "        reshape_data = ReshapeData()\n",
    "        reshape_data.process_and_reshape_data_v2(self.config.faster_rcnn_files_path)\n",
    "\n",
    "        metrics = Metrics()\n",
    "        metrics.metrics(predictions, self.config.annotations_path, self.true_annotation_labels, self.config.faster_rcnn_files_path)\n",
    "        metrics.call_metrics(self.config.faster_rcnn_files_path)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-23 17:42:48,280: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-11-23 17:42:48,294: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-11-23 17:42:48,296: INFO: common: created directory at: artifacts]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suraj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\suraj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_V2_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_stamp 0\n",
      "test_stamp 0\n",
      "test_stamp 0\n",
      "test_stamp 0\n",
      "test_stamp 0\n",
      "Macro F1 Score: 0.8714285714285713\n",
      "Micro F1 Score: 0.40531561461794013\n",
      "Micro-average Precision: 0.2837209302325581\n",
      "Micro-average Recall: 0.7093023255813954\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Evalaution.vote_validation() missing 1 required positional argument: 't_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     evaluate\u001b[38;5;241m.\u001b[39mvote_validation(test_set, images_name, predictions)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e \n",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m     evaluate\u001b[38;5;241m.\u001b[39mvisualize_predictions(predictions, test_set)\n\u001b[0;32m     10\u001b[0m     evaluate\u001b[38;5;241m.\u001b[39mmetrics_calculation(test_set,predictions)\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mevaluate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvote_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e \n",
      "\u001b[1;31mTypeError\u001b[0m: Evalaution.vote_validation() missing 1 required positional argument: 't_labels'"
     ]
    }
   ],
   "source": [
    "#pipeline\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    evaluation_config = config.get_evaluation_config() \n",
    "    evaluate = Evalaution(config=evaluation_config)\n",
    "    test_set, dataset_loader = evaluate.get_data_loader()\n",
    "    model = evaluate.get_faster_rcnn_model()\n",
    "    predictions,images_name=evaluate.make_predictions(dataset_loader, model)\n",
    "    evaluate.visualize_predictions(predictions, test_set)\n",
    "    evaluate.metrics_calculation(test_set,predictions)\n",
    "    evaluate.vote_validation(test_set, images_name, predictions)\n",
    "except Exception as e:\n",
    "    raise e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
