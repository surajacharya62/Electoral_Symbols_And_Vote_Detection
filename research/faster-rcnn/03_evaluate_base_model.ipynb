{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Oslo\\\\OsloMet\\\\Fourth semester\\\\Electoral_Symbols_And_Vote_Detection_MLOPS\\\\Electoral_Symbols_And_Vote_Detection\\\\research\\\\faster-rcnn'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Oslo\\\\OsloMet\\\\Fourth semester\\\\Electoral_Symbols_And_Vote_Detection_MLOPS\\\\Electoral_Symbols_And_Vote_Detection'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  #-------initializing the model----- \n",
    "\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class EvaluationConfig:\n",
    "    root_dir: Path\n",
    "    path_of_model: Path\n",
    "    test_images_path: Path\n",
    "    annotations_path: Path\n",
    "    faster_rcnn_files_path: Path\n",
    "    all_params: dict\n",
    "    mlflow_uri: str\n",
    "    params_image_size: list\n",
    "    params_batch_size: int\n",
    "    classes: int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules.symbol_detection.faster_rcnn.constants import *\n",
    "from src.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "                self,\n",
    "                config_filepath =  CONFIG_FILE_PATH,\n",
    "                params_filepath = PARAMS_FILE_PATH\n",
    "        ):\n",
    "            self.config = read_yaml(config_filepath)\n",
    "            self.params = read_yaml(params_filepath)\n",
    "\n",
    "            create_directories([self.config.artifacts_root])\n",
    "        \n",
    "        \n",
    "    def get_evaluation_config(self)->EvaluationConfig:\n",
    "      \n",
    "      config = self.config.base_models\n",
    "\n",
    "      eval_config = EvaluationConfig(\n",
    "                root_dir = Path(config.root_dir),\n",
    "                path_of_model=Path(config.model_path),\n",
    "                test_images_path=Path(config.test_images_path),\n",
    "                annotations_path=Path(config.annotations_path),\n",
    "                faster_rcnn_files_path=Path(config.faster_rcnn_files_path),\n",
    "                mlflow_uri=\"\",\n",
    "                all_params=self.params,\n",
    "                params_image_size=self.params.IMAGE_SIZE,\n",
    "                params_batch_size=self.params.BATCH_SIZE,\n",
    "                classes=self.params.CLASSES                \n",
    "          )\n",
    "      \n",
    "      return eval_config\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.symbol_detection.faster_rcnn.components.electoral_symbol_dataset import  ElectoralSymbolDataset\n",
    "from modules.symbol_detection.faster_rcnn.components.visualize_symbols_detection import VisualizePrediction\n",
    "from modules.symbol_detection.faster_rcnn.components.compare_bounding_boxes_faster import CompareBoundingBox\n",
    "from modules.symbol_detection.faster_rcnn.components.reshape_data import ReshapeData\n",
    "from modules.symbol_detection.faster_rcnn.components.metrics import Metrics\n",
    "from modules.vote_validation.faster_rcnn.validate_vote import ValidateVote\n",
    "from modules.symbol_detection.faster_rcnn.utils.faster_rcnn_utils import label_to_id,get_transform,collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "\n",
    "class Evalaution:  \n",
    "\n",
    "    def __init__(self, config:EvaluationConfig):\n",
    "        self.config = config\n",
    "        self.true_annotation_labels = label_to_id(self.config.annotations_path)\n",
    "\n",
    "    def get_data_loader(self):\n",
    "        annotation_labels = label_to_id(self.config.annotations_path)\n",
    "        test_set = ElectoralSymbolDataset(        \n",
    "            self.config.test_images_path,\n",
    "            \"single_image\",\n",
    "            self.config.annotations_path,\n",
    "            annotation_labels,\n",
    "            get_transform(train=False),\n",
    "            is_single_image=False \n",
    "        )\n",
    "        \n",
    "        test_data_loader = DataLoader(test_set, batch_size=self.config.params_batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "        return test_set, test_data_loader\n",
    "    \n",
    "    \n",
    "    def get_faster_rcnn_model(self):\n",
    "        \"\"\"\n",
    "        Initializing model  \n",
    "        \"\"\"\n",
    "        model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(pretrained=True)    \n",
    "        # get number of input features for the classifier\n",
    "        in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "        # replace the pre-trained head with a new one\n",
    "        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, self.config.classes) \n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def make_predictions(self,dataset_loader, faster_rcnn_model):\n",
    "        \"\"\"\n",
    "        Make predictions on test images\n",
    "        \"\"\"\n",
    "        \n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')       \n",
    "        faster_rcnn_model.load_state_dict(torch.load(self.config.path_of_model, map_location=device))\n",
    "        faster_rcnn_model.eval()\n",
    "        # test_data_loader = self.get_data_loader()\n",
    "       \n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for images, imageids, imagenames, target in dataset_loader:\n",
    "                images = [image.to(device) for image in images]\n",
    "                outputs = faster_rcnn_model(images)\n",
    "\n",
    "                for output, imageid, imagename in zip(outputs, imageids, imagenames):\n",
    "                    prediction = (output, imageid, imagename)\n",
    "                    predictions.append(prediction)\n",
    "        \n",
    "        test_images_path = self.config.test_images_path\n",
    "        test_images_name = []\n",
    "        for filename in os.listdir(test_images_path):\n",
    "            test_images_name.append(filename) \n",
    "        \n",
    "        return predictions, test_images_name\n",
    "    \n",
    "    \n",
    "    def visualize_predictions(self, predictions, test_set):\n",
    "        \"\"\"\n",
    "            Visualize prediction\n",
    "        \"\"\" \n",
    "            \n",
    "        visualize = VisualizePrediction()        \n",
    "        visualize.visualize_predicted_images(self.config.test_images_path, test_set, predictions, self.true_annotation_labels)\n",
    "    \n",
    "    \n",
    "    def vote_validation(self, test_set, test_images, predictions):\n",
    "        \n",
    "         #-------------Vote Validation\n",
    "\n",
    "        vote_validate = ValidateVote()        \n",
    "        vote_validate.validate_vote(test_set, test_images, predictions, self.true_annotation_labels, self.config.test_images_path)\n",
    "\n",
    "    \n",
    "    def metrics_calculation(self, test_set, predictions):\n",
    "    \n",
    "        #Predictions Bounding Box Comparison        \n",
    "        compare_bboxes = CompareBoundingBox()\n",
    "       \n",
    "        compare_bboxes.labels(test_set, predictions, self.true_annotation_labels) \n",
    "\n",
    "        #Data Reshaping\n",
    "        reshape_data = ReshapeData()\n",
    "        reshape_data.process_and_reshape_data_v2(self.config.faster_rcnn_files_path)\n",
    "\n",
    "        metrics = Metrics()\n",
    "        metrics.metrics(predictions, self.config.annotations_path, self.true_annotation_labels, self.config.faster_rcnn_files_path)\n",
    "        metrics.call_metrics(self.config.faster_rcnn_files_path)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-23 17:51:29,383: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-11-23 17:51:29,386: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-11-23 17:51:29,388: INFO: common: created directory at: artifacts]\n",
      "Length of dataset: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suraj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\suraj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_V2_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_stamp 0\n",
      "test_stamp 0\n",
      "test_stamp 0\n",
      "test_stamp 0\n",
      "test_stamp 0\n",
      "Macro F1 Score: 0.8714285714285713\n",
      "Micro F1 Score: 0.40531561461794013\n",
      "Micro-average Precision: 0.2837209302325581\n",
      "Micro-average Recall: 0.7093023255813954\n",
      "image_0000.jpg [42 22 25 26 10 20 18 12 16 32 33  8 28 38 41 27 24  3 19 40 17  9 36 21\n",
      " 14 23 13  4 15  6  7  2 31  1 37 30 43 34 11  5 29 35 39] 40 [(40, array([ 608., 2147.,  797., 2296.], dtype=float32))]\n",
      "Symbols{1: 'balance', 2: 'bus', 3: 'candle_light', 4: 'computer', 5: 'conch', 6: 'cycle', 7: 'damphu', 8: 'dog', 9: 'farmer', 10: 'hammer_scythe', 11: 'hand_palm', 12: 'heart', 13: 'hoe', 14: 'house', 15: 'key', 16: 'ladder', 17: 'lock', 18: 'lotus', 19: 'loud_speaker', 20: 'mother_and_child', 21: 'namaste', 22: 'nepali_big_basket', 23: 'nepali_cap', 24: 'nepali_jug', 25: 'nepali_madal', 26: 'nepali_small_basket', 27: 'owl', 28: 'pen', 29: 'roaster', 30: 'sheep', 31: 'star', 32: 'stick', 33: 'sun', 34: 'tiger', 35: 'torch_light', 36: 'tree', 37: 'turtle', 38: 'umbrella', 39: 'valid_stamp', 40: 'water_glass', 41: 'water_jug', 42: 'woman_man', 43: 'wooden_wheel'}\n",
      "Vote: lotus|invalid|invalid symbol or invalid stamp\n",
      "image_0001.jpg [11  4 15 29  8 25 18 38  1 41 17 32 20 36 10 42 27 22 24  6 37 28 16  7\n",
      " 12 43 23 21 34 26 30  3 40 13 31  2  5 19  9 33 14 35 39] 40 [(40, array([ 986., 2525., 1175., 2674.], dtype=float32))]\n",
      "Symbols{1: 'balance', 2: 'bus', 3: 'candle_light', 4: 'computer', 5: 'conch', 6: 'cycle', 7: 'damphu', 8: 'dog', 9: 'farmer', 10: 'hammer_scythe', 11: 'hand_palm', 12: 'heart', 13: 'hoe', 14: 'house', 15: 'key', 16: 'ladder', 17: 'lock', 18: 'lotus', 19: 'loud_speaker', 20: 'mother_and_child', 21: 'namaste', 22: 'nepali_big_basket', 23: 'nepali_cap', 24: 'nepali_jug', 25: 'nepali_madal', 26: 'nepali_small_basket', 27: 'owl', 28: 'pen', 29: 'roaster', 30: 'sheep', 31: 'star', 32: 'stick', 33: 'sun', 34: 'tiger', 35: 'torch_light', 36: 'tree', 37: 'turtle', 38: 'umbrella', 39: 'valid_stamp', 40: 'water_glass', 41: 'water_jug', 42: 'woman_man', 43: 'wooden_wheel'}\n",
      "Vote: star|invalid|invalid symbol or invalid stamp\n",
      "image_0002.jpg [32  5 40 34 31  9 10  2 29 41 30 37 23 19 11  7 28  1 21  8 17  3 24 16\n",
      " 12 20 36 18 42 15 27  6 13 43 35 14 25 26 38 33 22  4 39] 40 [(40, array([ 986., 1580., 1175., 1729.], dtype=float32))]\n",
      "Symbols{1: 'balance', 2: 'bus', 3: 'candle_light', 4: 'computer', 5: 'conch', 6: 'cycle', 7: 'damphu', 8: 'dog', 9: 'farmer', 10: 'hammer_scythe', 11: 'hand_palm', 12: 'heart', 13: 'hoe', 14: 'house', 15: 'key', 16: 'ladder', 17: 'lock', 18: 'lotus', 19: 'loud_speaker', 20: 'mother_and_child', 21: 'namaste', 22: 'nepali_big_basket', 23: 'nepali_cap', 24: 'nepali_jug', 25: 'nepali_madal', 26: 'nepali_small_basket', 27: 'owl', 28: 'pen', 29: 'roaster', 30: 'sheep', 31: 'star', 32: 'stick', 33: 'sun', 34: 'tiger', 35: 'torch_light', 36: 'tree', 37: 'turtle', 38: 'umbrella', 39: 'valid_stamp', 40: 'water_glass', 41: 'water_jug', 42: 'woman_man', 43: 'wooden_wheel'}\n",
      "Vote: ladder|invalid|invalid symbol or invalid stamp\n",
      "image_0003.jpg [27  2 22 35 36 32 15  6 37  8 38  5 34 26 24 28 41 21 31 18 17 43 42 13\n",
      " 11  9  7  4  1 30 19 23 40 16  3 25 12 33 20 29 10 14 39] 40 [(40, array([ 986., 2525., 1175., 2674.], dtype=float32))]\n",
      "Symbols{1: 'balance', 2: 'bus', 3: 'candle_light', 4: 'computer', 5: 'conch', 6: 'cycle', 7: 'damphu', 8: 'dog', 9: 'farmer', 10: 'hammer_scythe', 11: 'hand_palm', 12: 'heart', 13: 'hoe', 14: 'house', 15: 'key', 16: 'ladder', 17: 'lock', 18: 'lotus', 19: 'loud_speaker', 20: 'mother_and_child', 21: 'namaste', 22: 'nepali_big_basket', 23: 'nepali_cap', 24: 'nepali_jug', 25: 'nepali_madal', 26: 'nepali_small_basket', 27: 'owl', 28: 'pen', 29: 'roaster', 30: 'sheep', 31: 'star', 32: 'stick', 33: 'sun', 34: 'tiger', 35: 'torch_light', 36: 'tree', 37: 'turtle', 38: 'umbrella', 39: 'valid_stamp', 40: 'water_glass', 41: 'water_jug', 42: 'woman_man', 43: 'wooden_wheel'}\n",
      "Vote: sun|invalid|invalid symbol or invalid stamp\n",
      "image_0004.jpg [ 7 22  9 34 18  2  1  6 15 40 38 23 11 20 36 28 16 30 32 14 41 37 10 35\n",
      " 43 25  4 29 21 33 13  5  8 24 19 31  3 12 26 27 42 17 39] 40 [(40, array([1364., 1769., 1553., 1918.], dtype=float32))]\n",
      "Symbols{1: 'balance', 2: 'bus', 3: 'candle_light', 4: 'computer', 5: 'conch', 6: 'cycle', 7: 'damphu', 8: 'dog', 9: 'farmer', 10: 'hammer_scythe', 11: 'hand_palm', 12: 'heart', 13: 'hoe', 14: 'house', 15: 'key', 16: 'ladder', 17: 'lock', 18: 'lotus', 19: 'loud_speaker', 20: 'mother_and_child', 21: 'namaste', 22: 'nepali_big_basket', 23: 'nepali_cap', 24: 'nepali_jug', 25: 'nepali_madal', 26: 'nepali_small_basket', 27: 'owl', 28: 'pen', 29: 'roaster', 30: 'sheep', 31: 'star', 32: 'stick', 33: 'sun', 34: 'tiger', 35: 'torch_light', 36: 'tree', 37: 'turtle', 38: 'umbrella', 39: 'valid_stamp', 40: 'water_glass', 41: 'water_jug', 42: 'woman_man', 43: 'wooden_wheel'}\n",
      "Vote: nepali_jug|invalid|invalid symbol or invalid stamp\n"
     ]
    }
   ],
   "source": [
    "#pipeline\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    evaluation_config = config.get_evaluation_config() \n",
    "    evaluate = Evalaution(config=evaluation_config)\n",
    "    test_set, dataset_loader = evaluate.get_data_loader()\n",
    "    model = evaluate.get_faster_rcnn_model()\n",
    "    predictions,images_name=evaluate.make_predictions(dataset_loader, model)\n",
    "    evaluate.visualize_predictions(predictions, test_set)\n",
    "    evaluate.metrics_calculation(test_set,predictions)\n",
    "    evaluate.vote_validation(test_set, images_name, predictions)\n",
    "except Exception as e:\n",
    "    raise e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
